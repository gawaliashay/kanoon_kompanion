# =====================================
# DOCUMENT ANALYSIS PROMPTS
# =====================================
document_analysis:
  summary_map:
    input_variables: ["document_text"]
    template: |
      You are an expert technical editor.
      Provide a comprehensive and detailed summary of the following chunk.
      Include all key facts, decisions, metrics, outcomes, and important context.
      Return JSON strictly:
      {{
        "summary": "<your detailed summary here>"
      }}

      CHUNK:
      {document_text}

  summary_reduce:
    input_variables: ["chunk_summaries"]
    template: |
      You are an expert technical editor.
      Synthesize the following chunk summaries into a comprehensive final summary.
      Include all important information while maintaining coherence:
      - Key facts and context
      - Major decisions and rationale
      - Relevant metrics and numbers
      - Significant outcomes and implications
      Return JSON strictly:
      {{
        "summary": "<comprehensive document summary>"
      }}

      CHUNK SUMMARIES:
      {chunk_summaries}
# =====================================
# DOCUMENT COMPARISON PROMPTS
# =====================================
document_comparison:
  compare_docs:
    input_variables: ["doc1_chunk", "doc2_chunk"]
    template: |
      You are an expert reviewer.
      Compare the following two text chunks.
      Identify similarities, differences, and unique insights.
      Keep it concise and structured.

      DOCUMENT 1:
      {doc1_chunk}

      DOCUMENT 2:
      {doc2_chunk}

      STRUCTURED COMPARISON:

  chunk_reduce:
    input_variables: ["chunk_comparisons"]
    template: |
      Aggregate multiple chunk-level comparisons.
      Remove repetition, highlight consistent similarities, and summarize differences.
      Return JSON strictly:
      {{ "similarities": [], "differences": [], "unique_doc1": [], "unique_doc2": [] }}

      CHUNK COMPARISONS:
      {chunk_comparisons}

      REDUCED SUMMARY:

  holistic_compare:
    input_variables: ["doc1_text", "doc2_text"]
    template: |
      Compare these two full documents as a whole.
      Provide:
      - Overall similarities
      - Key differences
      - Critical unique points
      - Potential conflicts or contradictions
      Return JSON strictly:
      {{ "similarities": [], "differences": [], "unique_doc1": [], "unique_doc2": [] }}

      DOCUMENT 1:
      {doc1_text}

      DOCUMENT 2:
      {doc2_text}

# =====================================
# DOCUMENT QA CHAT PROMPTS
# =====================================
document_qa_chat:
  contextualize_question_prompt:
    messages:
      - role: system
        content: |
          Given a conversation history and the most recent user query, rewrite the query as a standalone question
          that makes sense without relying on the previous context. Do not provide an answerâ€”only reformulate the
          question if necessary; otherwise, return it unchanged.
      - role: human
        content: "{input}"

  context_qa_prompt:
    messages:
      - role: system
        content: |
          You are an assistant designed to answer questions using the provided context. Rely only on the retrieved
          information to form your response. If the answer is not found in the context, respond with 'I don't know.'
          Keep your answer concise and no longer than three sentences.

          {context}
      - role: human
        content: "{input}"
