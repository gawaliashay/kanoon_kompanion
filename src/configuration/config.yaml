# src\configuration\config.yaml

# =====================================
# API KEYS
# =====================================
api_keys:
  openai: ${OPENAI_API_KEY}
  mistral: ${MISTRAL_API_KEY}
  groq: ${GROQ_API_KEY}
  pinecone: ${PINECONE_API_KEY}
  huggingface: ${HUGGINGFACEHUB_API_TOKEN}
  google: ${GOOGLE_API_KEY}

# =====================================
# PATHS
# =====================================
paths:
  logs_dir: logs/
  cache_dir: cache/

  # analysis directory
  analysis_dir: data/analysis

  # comparison directory
  comparison_dir_a: data/comparison/set_a
  comparison_dir_b: data/comparison/set_b

  # document qa chat directory
  document_qa_chat_dir: data/document_qa_chat

# =====================================
# LOGGING & MONITORING
# =====================================
logging:
  level: INFO
  format: json
  enable_tracing: true

# =====================================
# CACHE CONFIG
# =====================================
cache:
  enabled: true
  backend: sqlite   # options: sqlite, redis, memory

# =====================================
# VECTORSTORES
# =====================================
vectorstores:
  default: faiss
  faiss:
    import_path: langchain_community.vectorstores.FAISS
    persist_directory: data/faiss_store
  chroma:
    import_path: langchain_community.vectorstores.Chroma
  pinecone:
    import_path: langchain_pinecone.Pinecone

# =====================================
# PREPROCESSING / INGESTION
# =====================================
preprocessing:
  lowercase: true
  strip_whitespace: true
  normalize_spaces: true
  remove_special_chars: false
  remove_numeric: false

  supported_exts:
    - ".pdf"
    - ".docx"
    - ".ppt"
    - ".pptx"
    - ".md"
    - ".txt"
    - ".csv"
    - ".xls"
    - ".xlsx"
    - ".sqlite"
    - ".db"

  loader_map:
    .pdf: langchain_community.document_loaders.PyPDFLoader
    .docx: langchain_community.document_loaders.Docx2txtLoader
    .ppt: langchain_community.document_loaders.UnstructuredPowerPointLoader
    .pptx: langchain_community.document_loaders.UnstructuredPowerPointLoader
    .md: langchain_community.document_loaders.UnstructuredMarkdownLoader
    .txt: langchain_community.document_loaders.TextLoader
    .csv: langchain_community.document_loaders.CSVLoader
    .xls: langchain_community.document_loaders.UnstructuredExcelLoader
    .xlsx: langchain_community.document_loaders.UnstructuredExcelLoader
    .sqlite: langchain_community.document_loaders.SQLLoader
    .db: langchain_community.document_loaders.SQLLoader

# =====================================
# TEXT SPLITTING CONFIGURATIONS
# =====================================
splitting_configs:
  default_strategy: recursive_character

  # General recursive character splitter
  recursive_character:
    import_path: langchain.text_splitter.RecursiveCharacterTextSplitter
    chunk_size: 1024
    chunk_overlap: 30
    separators: ["\n\n", "\n", " "]

  # Document Analysis
  analysis_strategy:
    import_path: langchain.text_splitter.RecursiveCharacterTextSplitter
    chunk_size: 1024
    chunk_overlap: 50
    separators: ["\n\n", "\n", " "]

  # Document Comparison
  document_comparison:
    import_path: langchain.text_splitter.RecursiveCharacterTextSplitter
    chunk_size: 600
    chunk_overlap: 100
    separators: ["\n\n", "\n", "â€¢", ".", ";"]
    is_separator_regex: false

  # Document QA Chat
  qa_strategy:
    import_path: langchain.text_splitter.TokenTextSplitter
    chunk_size: 512
    chunk_overlap: 50
    tokenizer_name: bert-base-uncased

# Mapping pipelines to their respective chunking strategies
pipeline_chunking_map:
  document_analysis: analysis_strategy
  document_comparison: document_comparison
  document_qa_chat: qa_strategy


# splitters:
#   recursive_character:
#     import_path: langchain.text_splitter.RecursiveCharacterTextSplitter
#     chunk_size: 1024
#     chunk_overlap: 50
#     separators: ["\n\n", "\n", ".", " "]
#     is_separator_regex: false

#   character:
#     import_path: langchain.text_splitter.CharacterTextSplitter
#     chunk_size: 1024
#     chunk_overlap: 30
#     separator: "\n\n"

#   token:
#     import_path: langchain.text_splitter.TokenTextSplitter
#     chunk_size: 512
#     chunk_overlap: 50
#     tokenizer_name: bert-base-uncased

#   markdown:
#     import_path: langchain.text_splitter.MarkdownTextSplitter
#     chunk_size: 1024
#     chunk_overlap: 30



# =====================================
# RETRIEVAL
# =====================================
retrieval:
  search_type: similarity
  similarity_top_k: 5

# =====================================
# ERROR HANDLING
# =====================================
llm_retries:
  max_attempts: 3
  backoff_factor: 2

# =====================================
# MODELS
# =====================================
defaults:
  llm: mistral
  embedding: huggingface

models:
  embeddings:
    huggingface:
      model_name: sentence-transformers/all-MiniLM-L6-v2
      #dimensions: 384
      import_path: langchain_huggingface.HuggingFaceEmbeddings
      #api_key: ${HUGGINGFACEHUB_API_TOKEN}

    openai:
      model_name: text-embedding-3-small
      dimensions: 1536
      import_path: langchain_openai.OpenAIEmbeddings
      api_key: ${OPENAI_API_KEY}

    google:
      model_name: models/embedding-001
      dimensions: 768
      import_path: langchain_google_genai.GoogleGenerativeAIEmbeddings
      api_key: ${GOOGLE_API_KEY}

  llms:
    groq:
      model_name: llama-3.1-8b-instant
      import_path: langchain_groq.ChatGroq
      api_key: ${GROQ_API_KEY}
      temperature: 0.3
      max_tokens: 128

    mistral:
      model_name: mistral-small
      import_path: langchain_mistralai.ChatMistralAI
      api_key: ${MISTRAL_API_KEY}
      temperature: 0.3
      max_tokens: 128

    openai:
      model_name: gpt-4o-mini
      import_path: langchain_openai.ChatOpenAI
      api_key: ${OPENAI_API_KEY}
      temperature: 0.7
      max_tokens: 128

    google:
      model_name: gemini-1.5-flash
      import_path: langchain_google_genai.ChatGoogleGenerativeAI
      api_key: ${GOOGLE_API_KEY}
      temperature: 0
      max_tokens: 128

# =====================================
# DOCUMENT ANALYSIS
# =====================================
document_analysis:
  enabled: true
  default_prompt: summary_map
  batch_size: 10
  chunk_fallback_length: 500

  steps:
    summary_map: true
    summary_reduce: true   # keywords removed

  output_format: json


# =====================================
# DOCUMENT COMPARISON
# =====================================
document_comparison:
  enabled: true
  default_prompt: compare_docs
  steps:
    compare_docs: true
    chunk_reduce: true
    holistic_compare: true
  output_format: json

  evaluation:
    enabled: true
    metrics:
      - relevance
      - consistency
      - faithfulness
    evaluator_llm: openai

# =====================================
# DOCUMENT QA CHAT
# =====================================
document_qa_chat:
  enabled: true
  default_prompt: contextualize_question_prompt
  batch_size: 10
  chunk_fallback_length: 500

  steps:
    contextualize_question_prompt: true
    context_qa_prompt: true

  output_format: json
